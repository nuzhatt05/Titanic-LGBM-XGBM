# LightGBM vs XGBoost - Titanic Dataset

This repository is focused on implementing and comparing **LightGBM** and **XGBoost** algorithms on the Titanic dataset.  
The assignment demonstrates preprocessing, model building, hyperparameter tuning, and comparative analysis of gradient boosting methods.

---

## Objective
To evaluate and compare the performance of **LightGBM** and **XGBoost** models for predicting Titanic passenger survival.  
This assignment provides hands-on practice with advanced gradient boosting algorithms and their optimization.

---

## Files Included

| File Name                  | Description |
| -------------------------- | ------------------------------------------------------------ |
| Titanic_LGBM_XGBM.ipynb     | Jupyter Notebook containing preprocessing, model implementation, hyperparameter tuning, and comparative analysis |
| LGBM & XGBM.docx           | Word document containing the problem statement and assignment details |
| Titanic_train.csv          | Training dataset used for model building |
| Titanic_test.csv           | Test dataset used for evaluation |

---

## Tools & Libraries
* Jupyter Notebook  
* Python 3.x  
* Libraries: `pandas`, `matplotlib`, `seaborn`, `scikit-learn`, `xgboost`, `lightgbm`  

---

## Tasks Performed
* **Exploratory Data Analysis (EDA):** checked missing values, visualized distributions, explored feature-survival relationships  
* **Data Preprocessing:** imputed missing values, applied encoding (One-Hot / Label Encoding), handled categorical variables  
* **Model Building:** trained and evaluated LightGBM and XGBoost models using train-test split  
* **Evaluation Metrics:** used accuracy, precision, recall, and F1-score for performance measurement  
* **Hyperparameter Tuning:** applied cross-validation and parameter optimization for both models  
* **Comparative Analysis:** compared LightGBM vs XGBoost performance metrics and visualized results  
* **Insights:** summarized strengths and weaknesses of each algorithm with practical implications  

---

## Status
Completed – dataset preprocessed, models implemented, hyperparameters tuned, and results compared.  
This assignment demonstrates how boosting methods differ in terms of speed, performance, and interpretability.  

---

## Author
**Nuzhat** – Data Science Learner  
GitHub: [nuzhatt05](https://github.com/nuzhatt05)
